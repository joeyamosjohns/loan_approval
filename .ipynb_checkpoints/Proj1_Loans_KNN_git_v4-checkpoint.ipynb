{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca44f2d-0e69-4fae-8af3-47fcf2cc2524",
   "metadata": {},
   "outputs": [],
   "source": [
    "##in this version i will say screw pipelines and just do it without for now ... \n",
    "#maybe I will see what this infinity issue is if I can inspect the resuly of each step manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1560cfb-6589-4bfe-9b8f-8103a1fa7925",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Round 1 cleaning complete. v1 decisions: keep all nan as new feature/value; no skew or outlier action has been taken\n",
    "##Round 1 exploration complete. (a) Distribution of each feature explored (b) feature-target and feature-feature relationships explored \n",
    "\n",
    "##Round 1 modelling Plan: make one model for each notebook, try to do systematic tuning ... take best few models (?) or is it too soon?\n",
    "##then go back and do feature engineering and feature selection based on these base-line models\n",
    "##Build pipe-line: dummies, scaling, tuning ...\n",
    "\n",
    "##next steps:\n",
    "##\n",
    "##Flask API Deployment\n",
    "##build small webpage interaction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1359efb1-103d-4360-a79d-3fceb18e9e4e",
   "metadata": {},
   "source": [
    "### Tuning of KNN \n",
    "\n",
    "Main parameters: k = num_neighbors, and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8ea7be-9e6e-4828-a3b3-c987068772ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## following https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3930bc-de41-4da9-b866-9925090d5c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "##brief review of KNN vs K-means ... \n",
    "##K-means (unspervised) has no labels, just feature space ... you create k-labels (choice of k is tricky and important)\n",
    "##then run thru k-means clustering algorithm to assign k-labels (clusters) to the data \n",
    "##b\n",
    "##KNN (supervised) is simpler because data already comes with p-labels (the role of k is different here) \n",
    "##in the training data on the test data you simply look at the k-nearet neighors (of training set) and take majority vote \n",
    "##on what label to assign to new point. The choice of k is important and the metric can change the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d36736eb-dfca-4e86-9fb5-5ac94b4893b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer, OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "\n",
    "#sns.set()\n",
    "sns.set(rc={'figure.figsize':(8,5)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98fec286-67d0-43e2-9388-f752a6f0cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning tool\n",
    "\n",
    "\n",
    "def perc_null(X):\n",
    "    \n",
    "    total = X.isnull().sum().sort_values(ascending=False)\n",
    "    data_types = X.dtypes\n",
    "    percent = (X.isnull().sum()/X.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "    missing_data = pd.concat([total, data_types, percent], axis=1, keys=['Total','Type' ,'Percent'])\n",
    "    return missing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ed78ec-e3a5-42c6-978d-f79aa86412ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0  Graduate            No   \n",
       "1  LP001003   Male     Yes          1  Graduate            No   \n",
       "2  LP001005   Male     Yes          0  Graduate           Yes   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/joejohns/Downloads/data_loans.csv\"\n",
    "\n",
    "data = pd.read_csv(path) \n",
    "print(data.shape)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63641633-d69d-4139-b4c9-6c46878e7554",
   "metadata": {},
   "source": [
    "## data processing from round 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753f03c8-e92b-4f38-8474-f52e6e5d7f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Credit_History', 'Self_Employed', 'LoanAmount', 'Dependents',\n",
       "       'Loan_Amount_Term', 'Gender', 'Married', 'Loan_ID', 'Education',\n",
       "       'ApplicantIncome', 'CoapplicantIncome', 'Property_Area', 'Loan_Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_null(data).index\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f80c7b0a-593c-4b8e-a460-f09ab9d24362",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {'ApplicantIncome':'Applicant_Income', 'CoapplicantIncome': 'Coapplicant_Income', 'LoanAmount':'Loan_Amount'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "559e805f-16fc-4026-b313-491a1701a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['Loan_Status']\n",
    "ID_feats = ['Loan_ID',] \n",
    "\n",
    "#feature types:\n",
    "\n",
    "numer_feats = ['Applicant_Income', 'Coapplicant_Income', 'Loan_Amount', 'Loan_Amount_Term',]\n",
    "\n",
    "ord_cat_feats = [ 'Dependents', 'Education', ]\n",
    "nom_cat_feats = ['Gender', 'Married', 'Self_Employed', 'Credit_History', 'Property_Area',]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdace83f-3706-4e64-b722-404e5008c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "##fix ordinal cats (write general function which does this, no ordinal encoder)\n",
    "for item in ['0', '1', '2', '3+']:\n",
    "    if item != '3+':\n",
    "        i = int(item)\n",
    "    else:\n",
    "        i = 3\n",
    "    data.loc[data['Dependents'] == item,'Dependents']  = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "631c4fb0-4309-4269-bbf7-f7750ad773bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix target; make it numeric; useful for regression modelling\n",
    "\n",
    "data.loc[data[\"Loan_Status\"] == 'Y', \"Loan_Status\"] = 1\n",
    "data.loc[data[\"Loan_Status\"] == 'N', \"Loan_Status\"] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b73e4da-77a9-4d88-a5a8-0b702ac04ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix this nom cat ... float --> string\n",
    "\n",
    "data.loc[data['Credit_History'] ==0.0, 'Credit_History'] = 'No'\n",
    "data.loc[data['Credit_History'] == 1.0, 'Credit_History'] = 'Yes'  #I use capitalized \"Yes\", \"No\" to be conistent with their other entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7496c6e1-90b7-4411-b98f-8e778a683a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn this into ordinal cat\n",
    "\n",
    "data.loc[data['Education']=='Not Graduate', \"Education\"] = 0\n",
    "data.loc[data['Education']=='Graduate', \"Education\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1c64910-edbc-46d3-99d9-62659a80e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up some feature lists for imputing and scaling \n",
    "\n",
    "#steps:\n",
    "\n",
    "#1. create new cat recording if NaN in specified numeric or nominal features \n",
    "#(do this before imputing of course)\n",
    "\n",
    "#numeric and nominal: \n",
    "#2. impute most_freq (Loan_Term)\n",
    "#3. impute mean (everyone else)\n",
    "#4. scale by max, min (or by mean; try both)\n",
    "\n",
    "#nominal cats:\n",
    "#5. get_dummies, nan yes\n",
    "#6. get_dummies, nan no\n",
    "\n",
    "impute_most_freq = ['Loan_Amount_Term']\n",
    "impute_mean = [x for x in ord_cat_feats+numer_feats if x not in impute_most_freq] \n",
    " \n",
    "scale = ord_cat_feats+numer_feats\n",
    "\n",
    "#can make a for loop that extracts these ... \n",
    "numer_ord_nan_new_cat = [ 'Loan_Amount', 'Loan_Amount_Term', 'Dependents', ] #make new category for these 'unk' = yes/no; ##impute by mean\n",
    "nom_cat_nan_dummies = ['Credit_History', 'Self_Employed', 'Gender', 'Married',]  ##make new dumies cat_val for nan\n",
    "nom_cat_dummies = ['Property_Area',]  #regular dummies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa8ad176-a4e1-4a66-a014-d8af99a01ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##carry out imputation and scaling steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "804b83ea-e508-4cb1-84d9-d0632c16a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1. create new categorical (records if any null values in any of specified cats)\n",
    "\n",
    "data['missing_data'] = 'No'  \n",
    "for feature in numer_ord_nan_new_cat:\n",
    "    data.loc[(data[feature].isnull()) , 'missing_data'] = 'Yes'\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6343741a-2797-4aa6-b9f9-9cd4e543df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update nom_cat_feats (no null values, ok)\n",
    "\n",
    "nom_cat_feats+= ['missing_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8006495d-c28e-4168-8520-94b4acd6e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general functions ... need testing; build simple df for various tests\n",
    "\n",
    "def most_freq_imputer(df, col_list): #data =df, list_col = [col1, col2, ...] columns of df\n",
    "    for col in col_list:\n",
    "        most_freq_val = df[col].value_counts().index[0]  #0 grabs most frequent\n",
    "        df.loc[df[col].isnull(), col] = most_freq_val\n",
    "\n",
    "\n",
    "def mean_imputer(df, col_list): #data =df, list_col = [col1, col2, ...] columns of df\n",
    "    for col in col_list:\n",
    "        mean = round(np.mean(df[col]),2)\n",
    "        df.loc[df[col].isnull(), col] = mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "942ffb0b-c06e-4ece-b82a-ad41ff06eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_min scaler\n",
    "\n",
    "def max_min_helper(x, min, max, new_min =0, new_max=1):\n",
    "    y = (x-min)/(max-min)   #scales to min = 0, max = 1\n",
    "    scaled = y*(new_max-new_min) + new_min \n",
    "    return scaled\n",
    "#scale by max \n",
    "\n",
    "def max_min_scaler(df, col_list, new_min =0, new_max=1):\n",
    "    for col in col_list:\n",
    "\n",
    "        min = np.min(df[col])\n",
    "        max = np.max(df[col])\n",
    "        \n",
    "        df[col] = df[col].map(lambda x: max_min_helper(x, min, max, new_min, new_max))\n",
    "                   \n",
    "    \n",
    "##why is this one not working? because you has max, min arguments switched in your function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "372dd2d6-7f9c-4139-9adc-1599e8876c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean scaler\n",
    "\n",
    "\n",
    "def mean_scaler(df, col_list):\n",
    "    for col in col_list:\n",
    "        mean = np.mean(df[col])\n",
    "        sigma = np.std(df[col]) #std deviation\n",
    "        df[col] = (df[col] - mean)/sigma\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96e185d3-2965-43d1-8532-4d1f69389477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tom</td>\n",
       "      <td>28.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jack</td>\n",
       "      <td>34.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steve</td>\n",
       "      <td>29.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ricky</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name   Age  Salary\n",
       "0    Tom  28.0    50.0\n",
       "1   Jack  34.0    50.0\n",
       "2  Steve  29.0    50.0\n",
       "3  Ricky  42.0     NaN\n",
       "4    NaN  29.0    60.0\n",
       "5   Jack   NaN    30.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##tests of these functions\n",
    "\n",
    "data_dic = {'Name':['Tom', 'Jack', 'Steve', 'Ricky',np.NaN, 'Jack'],'Age':[28,34,29,42, 29, np.NaN], \"Salary\":[50,50,50,np.NaN ,60,30]}\n",
    "df_testing = pd.DataFrame(data_dic)\n",
    "df_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e134a4f-48d3-4da9-ae41-4f01cdc766fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function most_freq_imputer at 0x7fab2a3eaca0>\n",
      "    Name   Age  Salary\n",
      "0    Tom  28.0    50.0\n",
      "1   Jack  34.0    50.0\n",
      "2  Steve  29.0    50.0\n",
      "3  Ricky  42.0     NaN\n",
      "4    NaN  29.0    60.0\n",
      "5   Jack   NaN    30.0\n",
      " \n",
      "    Name   Age  Salary\n",
      "0    Tom  28.0    50.0\n",
      "1   Jack  34.0    50.0\n",
      "2  Steve  29.0    50.0\n",
      "3  Ricky  42.0     NaN\n",
      "4   Jack  29.0    60.0\n",
      "5   Jack   NaN    30.0\n",
      "**** \n"
     ]
    }
   ],
   "source": [
    "for func in [most_freq_imputer ]:\n",
    "    col_list = ['Name']\n",
    "    df = df_fn_tests.copy()\n",
    "    print(func)\n",
    "    print(df)\n",
    "    func(df,col_list )\n",
    "    print(\" \")\n",
    "    print(df)\n",
    "    print(\"**** \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6b5d07b-0d06-4914-a7ca-8035e4a65220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function most_freq_imputer at 0x7fab2a3eaca0>\n",
      "    Name   Age  Salary\n",
      "0    Tom  28.0    50.0\n",
      "1   Jack  34.0    50.0\n",
      "2  Steve  29.0    50.0\n",
      "3  Ricky  42.0     NaN\n",
      "4    NaN  29.0    60.0\n",
      "5   Jack   NaN    30.0\n",
      " \n",
      "    Name   Age  Salary\n",
      "0    Tom  28.0    50.0\n",
      "1   Jack  34.0    50.0\n",
      "2  Steve  29.0    50.0\n",
      "3  Ricky  42.0    50.0\n",
      "4    NaN  29.0    60.0\n",
      "5   Jack  29.0    30.0\n",
      "**** \n",
      "<function mean_imputer at 0x7fab2a3eae50>\n",
      "    Name   Age  Salary\n",
      "0    Tom  28.0    50.0\n",
      "1   Jack  34.0    50.0\n",
      "2  Steve  29.0    50.0\n",
      "3  Ricky  42.0     NaN\n",
      "4    NaN  29.0    60.0\n",
      "5   Jack   NaN    30.0\n",
      " \n",
      "    Name   Age  Salary\n",
      "0    Tom  28.0    50.0\n",
      "1   Jack  34.0    50.0\n",
      "2  Steve  29.0    50.0\n",
      "3  Ricky  42.0    48.0\n",
      "4    NaN  29.0    60.0\n",
      "5   Jack  32.4    30.0\n",
      "**** \n",
      "<function max_min_scaler at 0x7fab2a3eaaf0>\n",
      "    Name   Age  Salary\n",
      "0    Tom  28.0    50.0\n",
      "1   Jack  34.0    50.0\n",
      "2  Steve  29.0    50.0\n",
      "3  Ricky  42.0     NaN\n",
      "4    NaN  29.0    60.0\n",
      "5   Jack   NaN    30.0\n",
      " \n",
      "    Name       Age    Salary\n",
      "0    Tom  0.000000  0.666667\n",
      "1   Jack  0.428571  0.666667\n",
      "2  Steve  0.071429  0.666667\n",
      "3  Ricky  1.000000       NaN\n",
      "4    NaN  0.071429  1.000000\n",
      "5   Jack       NaN  0.000000\n",
      "**** \n",
      "<function mean_scaler at 0x7fab2a40d040>\n",
      "    Name   Age  Salary\n",
      "0    Tom  28.0    50.0\n",
      "1   Jack  34.0    50.0\n",
      "2  Steve  29.0    50.0\n",
      "3  Ricky  42.0     NaN\n",
      "4    NaN  29.0    60.0\n",
      "5   Jack   NaN    30.0\n",
      " \n",
      "    Name       Age    Salary\n",
      "0    Tom -0.839964  0.204124\n",
      "1   Jack  0.305441  0.204124\n",
      "2  Steve -0.649063  0.204124\n",
      "3  Ricky  1.832649       NaN\n",
      "4    NaN -0.649063  1.224745\n",
      "5   Jack       NaN -1.837117\n",
      "**** \n"
     ]
    }
   ],
   "source": [
    "##tests\n",
    "\n",
    "#fortunately, all functions have same input function(df, col_list)\n",
    "for func in [most_freq_imputer, mean_imputer,  max_min_scaler, mean_scaler  ]:\n",
    "    col_list = ['Salary','Age']\n",
    "    df = df_fn_tests.copy()\n",
    "    print(func)\n",
    "    print(df)\n",
    "    func(df,col_list )\n",
    "    print(\" \")\n",
    "    print(df)\n",
    "    print(\"**** \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0783b92-e910-421d-b90f-0fac5eda6dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f9b97b8-8ba4-41b1-b67f-7847ae7aecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##impute most frequent \n",
    "\n",
    "most_freq_val = data['Loan_Amount_Term'].value_counts().index[0].copy()  #0 grabs most frequent\n",
    "\n",
    "data.loc[data['Loan_Amount_Term'].isnull(), 'Loan_Amount_Term'] = most_freq_val\n",
    "\n",
    "#for feat in impute_most_freq:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3048d6e-d3f2-4c66-8831-2d311f0c87fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that col has no null\n",
    "#perc_null(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1ab5c72-1397-42dd-8d04-afe7e8c9df50",
   "metadata": {},
   "outputs": [],
   "source": [
    "##impute mean # start on one column\n",
    "\n",
    "mean = round(np.mean(data['Loan_Amount']),2)\n",
    "\n",
    "data.loc[data['Loan_Amount'].isnull(), 'Loan_Amount'] = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3d19e66e-b4fb-4f07-b14e-bce4fac0575a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.198857\n",
       "1      0.172214\n",
       "2      0.082489\n",
       "3      0.160637\n",
       "4      0.191027\n",
       "         ...   \n",
       "609    0.089725\n",
       "610    0.044863\n",
       "611    0.353111\n",
       "612    0.257598\n",
       "613    0.179450\n",
       "Name: Loan_Amount, Length: 614, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test on one column\n",
    "\n",
    "\n",
    "def max_min_scale(x, max, min, new_min =0, new_max=1):\n",
    "    y = (x-min)/(max-min)   #scales to min = 0, max = 1\n",
    "    scaled = y*(new_max-new_min) + new_min \n",
    "    return scaled\n",
    "\n",
    "df = data.copy()\n",
    "col = 'Loan_Amount'\n",
    "\n",
    "max = np.max(df[col])\n",
    "min = np.min(df[col])\n",
    "\n",
    "df[col].map(lambda x: max_min_scale(x, max, min, new_min =0, new_max =1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9bf1d484-6684-434c-b941-aae18fb3505d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.000025\n",
       "1     -0.219272\n",
       "2     -0.957640\n",
       "3     -0.314546\n",
       "4     -0.064453\n",
       "         ...   \n",
       "609   -0.898094\n",
       "610   -1.267278\n",
       "611    1.269372\n",
       "612    0.483368\n",
       "613   -0.159727\n",
       "Name: Loan_Amount, Length: 614, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test mean scaler on single column \n",
    "\n",
    "df = data.copy()\n",
    "col = 'Loan_Amount'\n",
    "\n",
    "mean = np.mean(df[col])\n",
    "sigma = np.std(df[col]) #std deviation\n",
    "(df[col] - mean)/sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67643541-c02f-4014-8ece-86159243d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataframeTransformer():\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        return self.func(input_df)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "# this function takes a dataframe as input and\n",
    "# returns a modified version thereof\n",
    "def get_dummies_dataframe(input_df):\n",
    "    return pd.get_dummies(input_df, columns = nom_cat_feats)\n",
    "\n",
    "\n",
    "# this pipeline has a single step\n",
    "pipeline = Pipeline([\n",
    "    (\"get_dummies\", DataframeTransformer(get_dummies_dataframe))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011ea416-41cf-4163-bd1f-d395b5818410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let me now follow https://machinelearningmastery.com/modeling-pipeline-optimization-with-scikit-learn/\n",
    "#which does cv = 3 instead of cv = stratififedkfold( ... )\n",
    "\n",
    "model_feats = ord_cat_feats+nom_cat_feats+num_feats\n",
    "\n",
    "y = data.loc[:, target]\n",
    "X= data.loc[:, model_feats]\n",
    "\n",
    "# Split the data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,  \n",
    "    y, \n",
    "    test_size=1/3,\n",
    "    random_state=0)\n",
    " \n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "#np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bcea01-a536-4726-8ece-648bfa50ed8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d169b6-3de0-43c8-bd02-27e8b59285a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e2015-16db-477d-a9ba-613ad9bef4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_null(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603d3275-38f5-4323-83c4-9bc486fd42ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960dee34-73a8-4826-b3ca-92178ce83664",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep = preprocess.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52877b20-cc08-4521-bf8b-44dbc88c9c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep  #hmm ColumnTransformer returns an array ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5582b265-decb-4559-9526-0c4cbe68637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_train_prep, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd904b7c-ec70-4a81-88d5-a26c9d2287b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn = pipeline.fit(X_train, y_train)\n",
    "print('Training set score: ' + str(knn.score(X_train,y_train)))\n",
    "print('Test set score: ' + str(knn.score(X_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb2ae9a-7817-458c-b8a3-b8d7b98d5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "what ... the fuck... it seems there is an infinite value (or too large)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
